# Chapter 17 - Building an Autonomous Car in Under an Hour: Reinforcement Learning with AWS DeepRacer

Note: All images in this directory, unless specified otherwise, are licensed under [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/legalcode).

## Figure List

| Figure number | Description |
|:---|:---|
| [17-1](https://www.amazon.com/AWS-DeepRacer-Fully-autonomous-developers/dp/B07JMHRKQG) | The AWS DeepRacer one-eighteenth-scale autonomous car |
| [17-2](2-aws-console.png) | The AWS login console |
| [17-3](3-training-workflow.png) | Workflow for training the AWS DeepRacer model |
| [17-4](4-model-creation.png) | Creating a model on the AWS DeepRacer console |
| [17-5](5-track-selection.png) | Track selection on the AWS DeepRacer console |
| [17-6](6-action-space.png) | Defining the action space on the AWS DeepRacer console |
| [17-7](7-reward-function-params.png) | Reward function parameters (a more in-depth review of these parameters is available in the documentation) |
| [17-8](8-reward-params-explained.png) | Visual explanation of some of the reward function parameters |
| [17-9](9-example-reward-function.png) | An example reward function |
| [17-10](10-training-graph.png) | Training graph and simulation video stream on the AWS DeepRacer console |
| [17-11](11-model-evaluation.png) | Model evaluation page on the AWS DeepRacer console |
| [17-12](12-reinforcement-learning-nutshell.png) | Reinforcement learning theory basics in a nutshell |
| [17-13](13-deepracer-training-flow.png) | The DeepRacer training flow |
| [17-14](14-agent-exploring-illustration.png) | Illustration of an agent exploring during an episode |
| [17-15](15-different-paths-to-goal.png) | Illustration of different paths to the goal |
| [17-16](16-vanilla-policy-gradient.png) | Training process for the vanilla policy gradient algorithm |
| [17-17](17-ppo-algorithm-training.png) | Training using the PPO algorithm |
| [17-18](18-heatmap-visualization.png) | Heatmap visualization for the example centerline reward function |
| [17-19](19-speed-heatmap.png) | Speed heatmap of an evaluation run; (left) evaluation lap with the basic example reward function, (right) faster lap with modified reward function |
| [17-20](20-test-track-layout.png) | The test track layout |
| [17-21](21-model-upload-menu.png) | The Model upload menu on the AWS DeepRacer car web console |
| [17-22](22-driving-mode-selection-menu.png) | Driving mode selection menu on the AWS DeepRacer car web console |
| [17-23](23-model-selection-menu.png) | Model selection menu on AWS DeepRacer car web console |
| [17-24](24-gradcam-heatmaps.png) | GradCAM heatmaps for AWS DeepRacer navigation |
| [17-25](https://www.duckietown.org/research/ai-driving-olympics) | Duckietown at the AI Driving Olympics |
| [17-26](https://www.gtplanet.net/forum/threads/roborace-robocar-2016.390791/) | Robocar from Roborace designed by Daniel Simon (image courtesy of Roborace) |