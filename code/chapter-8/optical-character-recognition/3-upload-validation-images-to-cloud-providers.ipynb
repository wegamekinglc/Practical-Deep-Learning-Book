{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud APIs for Computer Vision: Up and Running in 15 Minutes\n",
    "\n",
    "This code is part of [Chapter 8- Cloud APIs for Computer Vision: Up and Running in 15 Minutes ](https://learning.oreilly.com/library/view/practical-deep-learning/9781492034858/ch08.html).\n",
    "\n",
    "## Upload Validation Images to Cloud Providers\n",
    "\n",
    "In this file we will gather the data that enables us to do the benchmarking. We will be using the Google, Microsoft, and Amazon cloud providers so make sure you register and generate an API key for each and replace it in the [`optical-character-recognition`](https://github.com/PracticalDL/Practical-Deep-Learning-Book/blob/master/code/chapter-8/experiment-scripts/optical-character-recognition) directory. \n",
    "\n",
    "We have already moved a portion of the MSCOCO images to a separate folder, so let's provide that location in the following cells at `legible_images_path`. Update the absolute path to the `data` directory (example: `data-may-2020`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"<PATH_TO_DATA_DIR>\"\n",
    "legible_images_path = data_path + \"/legible-images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_output_path = data_path + \"/google-ocr-jsondump.json\"\n",
    "!python ../experiment-scripts/optical-character-recognition/google.py -d $legible_images_path -o $google_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microsoft_recognition_ids_path = data_path + \"/msft-recognition-ids.txt\"\n",
    "!python ../experiment-scripts/optical-character-recognition/microsoft-phase-1.py -d $legible_images_path > $microsoft_recognition_ids_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "microsoft_output_path = data_path + \"/msft-ocr-jsondump.json\"\n",
    "!python ../experiment-scripts/optical-character-recognition/microsoft-phase-2.py -i $microsoft_recognition_ids_path -o $microsoft_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_output_path = data_path + \"/amazon-ocr-jsondump.json\"\n",
    "!python ../experiment-scripts/optical-character-recognition/amazon.py -d $legible_images_path -o $amazon_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the collected data to see which cloud provider is the best. We have also provided our versions of the above files in the `data-nov-2019` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
